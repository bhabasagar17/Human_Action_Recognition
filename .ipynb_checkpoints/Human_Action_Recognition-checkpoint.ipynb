{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9008f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sagar\n",
    "# We will use a public dataset called \"UCF50\". \n",
    "# This dataset was published by University of Central Florida and contain 50 action classes.\n",
    "# Below is the link to datset\n",
    "# https://www.crcv.ucf.edu/data/UCF50.php\n",
    "# All the classes have time series pictures/video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a08bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install tensorflow if you haven't already\n",
    "!pip install tensorflow opencv-contrib-python pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d833f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import os\n",
    "import cv2\n",
    "#import pafy\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c925c685",
   "metadata": {},
   "source": [
    "Set Numpy, Python, and Tensorflow seeds to get consistent results on every run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e1ee077",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_constant = 15\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1042c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a Matplotlib figure size 16*16.\n",
    "plt.figure(figsize = (20, 20))\n",
    "\n",
    "# Lets get names of all categories in UCF50.\n",
    "all_classes_names = os.listdir('UCF50')\n",
    "\n",
    "#We are only interested in 20 classes. If you have enough time and computing power you can select all 50.\n",
    "# Generate a list of 20 random values. The values will be between 0-50, \n",
    "# where 50 is the total number of class in the dataset. \n",
    "random_range = random.sample(range(len(all_classes_names)), 50)\n",
    "\n",
    "# Iterating through all the generated random values.\n",
    "for counter, random_index in enumerate(random_range, 1):\n",
    "\n",
    "    # Retrieve a Class Name using the Random Index.\n",
    "    selected_class_Name = all_classes_names[random_index]\n",
    "\n",
    "    # Retrieve the list of all the video files present in the randomly selected Class Directory.\n",
    "    video_files_names_list = os.listdir(f'UCF50/{selected_class_Name}')\n",
    "\n",
    "    # Randomly select a video file from the list retrieved from the randomly selected Class Directory.\n",
    "    selected_video_file_name = random.choice(video_files_names_list)\n",
    "\n",
    "    # Initialize a VideoCapture object to read from the video File.\n",
    "    video_reader = cv2.VideoCapture(f'UCF50/{selected_class_Name}/{selected_video_file_name}')\n",
    "    \n",
    "    # Read the first frame of the video file.\n",
    "    _, bgr_frame = video_reader.read()\n",
    "\n",
    "    # Release the VideoCapture object. \n",
    "    video_reader.release()\n",
    "\n",
    "    # Convert the frame from BGR into RGB format. \n",
    "    rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Write the class name on the video frame.\n",
    "    cv2.putText(rgb_frame, selected_class_Name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    \n",
    "    # Display the frame.\n",
    "    plt.subplot(3, 3, counter);plt.imshow(rgb_frame);plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e85cedd",
   "metadata": {},
   "source": [
    "Preparing dataset\n",
    "we will read videos and resize all frames to a specific size. this reduces computation.\n",
    "We will then normalise data by dividing with 255 in range of [0 and 1].\n",
    "this will make convergance faster durning network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef5ae5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resized in our dataset.\n",
    "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
    "\n",
    "#Number of frames that we will feed to our model\n",
    "SEQUENCE_LENGTH = 20\n",
    "# Specify the directory containing the UCF50 dataset. \n",
    "DATASET_DIR = \"UCF50\"\n",
    "\n",
    "# Specify the list containing the names of the classes used for training. Feel free to choose any set of classes.\n",
    "CLASSES_LIST = [\"TaiChi\", \"PizzaTossing\", \"JumpRope\", \"HorseRace\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f25539",
   "metadata": {},
   "source": [
    "Lets create a function to Extract, Resize and Normalize each frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cdbae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_extraction(video_path):\n",
    "    # Make a list\n",
    "    frames_list = []\n",
    "    # read path\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    #Get number of frames\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    #Interval after which frames will be added to the list.\n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
    "    # Iterate through the Video Frames.\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    "        # Set the current frame position of the video.\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "        # Reading the frame from the video. \n",
    "        success, frame = video_reader.read() \n",
    "        # Check if Video frame is not successfully read then break the loop\n",
    "        if not success:\n",
    "            break\n",
    "        # Resize the Frame to fixed height and width.\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))        \n",
    "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "        normalized_frame = resized_frame / 255        \n",
    "        # Append the normalized frame into the frames list\n",
    "        frames_list.append(normalized_frame)   \n",
    "    # Release the VideoCapture object. \n",
    "    video_reader.release()\n",
    "    # Return the frames list.\n",
    "    return frames_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169555b",
   "metadata": {},
   "source": [
    "Function to create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9812cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    # Declared Empty Lists to store the features, labels and video file path values.\n",
    "    features = []\n",
    "    labels = []\n",
    "    video_files_paths = []    \n",
    "    # Iterating through all the classes mentioned in the classes list\n",
    "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
    "        \n",
    "        # Display the name of the class whose data is being extracted.\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "        \n",
    "        # Get the list of video files present in the specific class name directory.\n",
    "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
    "        \n",
    "        # Iterate through all the files present in the files list.\n",
    "        for file_name in files_list:\n",
    "            \n",
    "            # Get the complete video path.\n",
    "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
    "\n",
    "            # Extract the frames of the video file.\n",
    "            frames = frames_extraction(video_file_path)\n",
    "\n",
    "            # Check if the extracted frames are equal to the SEQUENCE_LENGTH specified above.\n",
    "            # So ignore the vides having frames less than the SEQUENCE_LENGTH.\n",
    "            if len(frames) == SEQUENCE_LENGTH:\n",
    "\n",
    "                # Append the data to their repective lists.\n",
    "                features.append(frames)\n",
    "                labels.append(class_index)\n",
    "                video_files_paths.append(video_file_path)\n",
    "\n",
    "    # Converting the list to numpy arrays\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)  \n",
    "    \n",
    "    # Return the frames, class index, and video file path.\n",
    "    return features, labels, video_files_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0545ceef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: TaiChi\n",
      "Extracting Data of Class: PizzaTossing\n",
      "Extracting Data of Class: JumpRope\n",
      "Extracting Data of Class: HorseRace\n"
     ]
    }
   ],
   "source": [
    "# Lets create the dataset.\n",
    "features, labels, video_files_paths = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d4e5cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert labels into one-hot-encoded vectors\n",
    "one_hot_encoded_labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588aadc4",
   "metadata": {},
   "source": [
    "Split the Data into Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "455e5b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Data into Train ( 70% ) and Test Set ( 30% ).\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels,\n",
    "                                                                            test_size = 0.25, shuffle = True,\n",
    "                                                                            random_state = seed_constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a467b588",
   "metadata": {},
   "source": [
    "Construct a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68045e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LRCN_model():\n",
    "    # We will use a Sequential model for model construction.\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(16, (3, 3), padding='same',activation = 'relu'),\n",
    "                              input_shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
    "    \n",
    "    model.add(TimeDistributed(MaxPooling2D((4, 4)))) \n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((4, 4))))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))                                    \n",
    "    model.add(TimeDistributed(Flatten()))                                      \n",
    "    model.add(LSTM(32))                                      \n",
    "    model.add(Dense(len(CLASSES_LIST), activation = 'softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72259c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the required LRCN model.\n",
    "LRCN_model = create_LRCN_model()\n",
    "\n",
    "# Display the success message.\n",
    "print(\"Model Created Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5117db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the structure of the contructed LRCN model.\n",
    "plot_model(LRCN_model, to_file = 'LRCN_model_structure_plot.png', show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c79390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Instance of Early Stopping Callback.\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 15, mode = 'min', restore_best_weights = True)\n",
    " \n",
    "# Compile the model and specify loss function, optimizer and metrics to the model.\n",
    "LRCN_model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "# Start training the model.\n",
    "LRCN_model_training_history = LRCN_model.fit(x = features_train, y = labels_train, epochs = 10, batch_size = 4 ,\n",
    "                                             shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model.\n",
    "model_evaluation_history = LRCN_model.evaluate(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09987f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the loss and accuracy from model_evaluation_history.\n",
    "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
    "\n",
    "# Define the string date format.\n",
    "# Get the current Date and Time in a DateTime Object.\n",
    "# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n",
    "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "current_date_time_dt = dt.datetime.now()\n",
    "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "    \n",
    "# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n",
    "model_file_name = f'LRCN_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
    "\n",
    "# Save the Model.\n",
    "LRCN_model.save(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training and validation loss metrices.\n",
    "plot_metric(LRCN_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a310cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training and validation accuracy metrices.\n",
    "plot_metric(LRCN_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf4a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = load_model('model.h5')\n",
    "# summarize model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d19428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
